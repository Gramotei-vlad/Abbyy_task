# Abbyy_task
Описание
--
Эксперименты на датасете [conll2003](https://huggingface.co/datasets/conll2003) для
задания на ABBYY курсе.

Установка
--
Склонируйте репозиторий в colab или себе на комп и установите
нужные библиотеки 
```
   pip install -r requirements.txt
```

Обучение
--
Чтобы начать обучать модель, то введите команду ниже
```
   python main.py
```
Команда выше запустит LSTM модель с кросс-энтропией. 
Параметры обучения можно глянуть в main.py.

Графики обучения
--
Графики обучения можно глянуть [здесь](https://wandb.ai/v-kosukhin/Abbyy_task?workspace=user-v-kosukhin)


Результаты на тестовом наборе данных.
--

Кросс-энтропия + веса классов;

               precision   recall   f1-score


           '       0.86      1.00      0.92
    PAD_TOKEN      1.00      1.00      1.00      
           B       0.81      0.89      0.85      
          BD       0.95      0.91      0.93      
          BG       0.82      0.91      0.86       
          BN       0.75      0.88      0.81     
          BP       0.83      0.90      0.87       
          BR       0.53      0.48      0.51       
          BS       0.78      0.88      0.82         
          BZ       0.82      0.91      0.86       
           C       0.99      1.00      1.00       
           D       0.96      0.94      0.95      
          DT       0.92      0.92      0.92       
           H       0.43      1.00      0.60         
           J       0.78      0.77      0.78      
          JR       0.66      0.76      0.71       
          JS       0.80      0.94      0.87       
           N       0.88      0.89      0.89     
          NP       0.89      0.85      0.87     
         NPS       0.28      0.60      0.38       
          NS       0.92      0.92      0.92      
           O       1.00      1.00      1.00       
          OS       1.00      0.96      0.98       
           P       0.78      0.93      0.85       
          P$       1.00      1.00      1.00        
          RB       1.00      1.00      1.00        
          RP       0.97      0.99      0.98       
         RP$       1.00      0.99      0.99       
           S       0.00      0.00      0.00         
           T       0.99      0.99      0.99      
           W       0.34      0.73      0.47        
           X       0.97      0.94      0.96        
          YM       0.98      0.96      0.97 
           _       1.00      1.00      1.00

    micro avg      0.91      0.92      0.92
    macro avg      0.81      0.88      0.84
    weighted avg   0.92      0.92      0.92


Focal loss;

                 precision  recall  f1-score

           '       0.86      1.00      0.92
    PAD_TOKEN      1.00      1.00      1.00
           B       0.81      0.87      0.84
          BD       0.96      0.91      0.93
          BG       0.83      0.89      0.86
          BN       0.74      0.89      0.81
          BP       0.82      0.92      0.87
          BR       0.65      0.51      0.57
          BS       0.89      0.89      0.89
          BZ       0.83      0.91      0.87
           C       0.99      1.00      1.00
           D       0.95      0.94      0.95
          DT       0.92      0.94      0.93
           H       0.43      1.00      0.60
           J       0.78      0.76      0.77
          JR       0.62      0.77      0.69
          JS       0.79      0.96      0.86
           N       0.88      0.89      0.88
          NP       0.88      0.85      0.87
         NPS       0.24      0.49      0.33
          NS       0.92      0.92      0.92
           O       1.00      1.00      1.00
          OS       1.00      0.96      0.98
           P       0.78      0.92      0.84
          P$       1.00      1.00      1.00
          RB       0.99      1.00      0.99
          RP       0.98      0.99      0.98
         RP$       1.00      0.99      0.99
           S       0.00      0.00      0.00
           T       0.98      0.99      0.99
           W       0.38      0.92      0.53
           X       0.97      1.00      0.99
          YM       0.98      0.96      0.97
           _       1.00      1.00      1.00

    micro avg      0.91      0.92      0.91
    macro avg      0.82      0.88      0.84
    weighted avg   0.91      0.92      0.91


Cross entropy;

                precision   recall   f1-score

           '       0.86      1.00      0.92
    PAD_TOKEN      0.99      0.99      0.99
           B       0.82      0.88      0.85
          BD       0.93      0.94      0.93
          BG       0.82      0.90      0.86
          BN       0.84      0.82      0.83
          BP       0.82      0.91      0.86
          BR       0.42      0.69      0.52
          BS       0.67      0.86      0.75
          BZ       0.81      0.93      0.87
           C       0.99      1.00      1.00
           D       0.95      0.94      0.94
          DT       0.92      0.93      0.93
           H       0.43      1.00      0.60
           J       0.77      0.79      0.78
          JR       0.83      0.76      0.79
          JS       0.82      0.90      0.86
           N       0.88      0.89      0.89
          NP       0.89      0.85      0.87
         NPS       0.39      0.58      0.47
          NS       0.92      0.92      0.92
           O       1.00      1.00      1.00
          OS       0.99      0.96      0.97
           P       0.83      0.91      0.87
          P$       1.00      1.00      1.00
          RB       0.99      1.00      0.99
          RP       0.99      0.99      0.99
         RP$       1.00      1.00      1.00
           S       0.04      1.00      0.08
           T       0.99      0.99      0.99
           W       0.34      0.73      0.47
           X       0.97      1.00      0.99
          YM       0.98      0.93      0.95
           _       1.00      1.00      1.00

    micro avg       0.91      0.92      0.92
    macro avg       0.82      0.91      0.84
    weighted avg    0.92      0.92      0.92


Получение результатов на тесте.
--

Обученные модели лежат [здесь](https://drive.google.com/drive/folders/18_H1CfXR3K2kh3NAzQ07ndfELDERbCLG?usp=sharing)
Чтобы прогнать модель на тесте, введите команду 
```
   python main.py --inference --inference_model_path=<Директория с tf моделью>
```

Получение результатов на свое строке.
--
Если нужно получить предсказания для собственной строки, то введите команду ниже. 
Слова в строке должны быть разделены пробелом.
```
   python main.py --predict --input="She saw a cat" --inference_model_path=<Путь до модели>
```

Классический подход
--

Вместо нейронкой можно попробовать предсказывать классическим
алгоритмом.

Результаты на тесте. 
        
                precision   recall   f1-score 

           '       1.00      0.86      0.92
           B       0.85      0.79      0.82
          BD       0.92      0.91      0.91
          BG       0.93      0.70      0.80
          BN       0.80      0.76      0.78
          BP       0.91      0.77      0.84
          BR       0.58      0.42      0.49
          BS       0.33      0.33      0.33
          BZ       0.94      0.80      0.86
           C       1.00      1.00      1.00
           D       0.90      0.72      0.80
          DT       0.92      0.69      0.79
           H       0.83      0.71      0.77
           J       0.81      0.69      0.75
          JR       0.69      0.75      0.72
          JS       0.84      0.75      0.79
           N       0.79      0.82      0.81
          NP       0.73      0.73      0.73
         NPS       0.85      0.42      0.56
          NS       0.95      0.80      0.87
           O       1.00      0.99      0.99
          OS       0.96      1.00      0.98
           P       0.81      0.81      0.81
          P$       1.00      1.00      1.00
          RB       0.92      0.99      0.95
          RP       0.92      0.98      0.95
         RP$       0.98      1.00      0.99
           S       0.33      0.04      0.08
           T       0.81      0.98      0.89
           W       0.39      0.50      0.44
           X       0.86      0.91      0.89
          YM       1.00      0.98      0.99
           _       0.99      0.99      0.99

     micro avg     0.85      0.83      0.84
     macro avg     0.83      0.78      0.80
     weighted avg  0.85      0.83      0.84

Чтобы получить результат классического алгоритма, нужно 
запустить команду ниже.

```
   python3 classical_approaches/classic_main.py
```

Чтобы прогнать свою строку через классику, нужно ввести
команду ниже

```
   python3 classical_approaches/classic_main.py --predict --input="She saw a dog"
```